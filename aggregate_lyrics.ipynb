{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius\n",
    "import pandas as pd\n",
    "\n",
    "# Tu token de autenticación (Bearer Token)\n",
    "token = \"tyVAyvo90CltRuI4bfPbK4VS_dipGtrHFtIPWtaY_NRDkuvGUpsG158goOTn\"\n",
    "\n",
    "# Inicializa la instancia de Genius\n",
    "genius = lyricsgenius.Genius(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lyricsgenius\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def fetch_lyrics(track_name, artist_name, genius, no_lyrics):\n",
    "    try:\n",
    "        song = genius.search_song(track_name, artist_name)\n",
    "        if song:\n",
    "            return song.lyrics\n",
    "        else:\n",
    "            no_lyrics.append((track_name, artist_name))\n",
    "            return None\n",
    "    except:\n",
    "        no_lyrics.append((track_name, artist_name))\n",
    "        return None\n",
    "\n",
    "def process_batch(batch_df, genius, no_lyrics, pause_time):\n",
    "    lyrics = []\n",
    "    for index, row in batch_df.iterrows():\n",
    "        lyrics.append(fetch_lyrics(row['track_name'], row['artist_name'], genius, no_lyrics))\n",
    "        if pause_time > 0:\n",
    "            time.sleep(pause_time)  # Pausa entre solicitudes para no sobrecargar la API\n",
    "    return pd.Series(lyrics, index=batch_df.index)\n",
    "\n",
    "def get_lyrics(df, batch_size=200, pause_time=0.2, n_jobs=6, token=\"NTWXUPKn3DXfY9SIpoX30G0HVcjH3GSskIk0KURIsxXQaXjCr0ljIq5IyLA5y7p0\"):\n",
    "    # Inicializa la instancia de Genius\n",
    "    genius = lyricsgenius.Genius(token)\n",
    "    no_lyrics = []\n",
    "\n",
    "    # Dividir el DataFrame en lotes\n",
    "    batches = [df.iloc[i:i + batch_size] for i in range(0, len(df), batch_size)]\n",
    "    total_batches = len(batches)\n",
    "    half_batches = total_batches // 2\n",
    "\n",
    "    # Procesar cada lote en paralelo\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_batch)(batch, genius, no_lyrics, pause_time) for batch in tqdm(batches, desc=\"Procesando lotes\")\n",
    "    )\n",
    "    \n",
    "    # Imprimir progreso al 50%\n",
    "    if half_batches > 0:\n",
    "        print(\"50% del procesamiento completado.\")\n",
    "\n",
    "    # Concatenar los resultados de todos los lotes en una sola columna\n",
    "    lyrics_series = pd.concat(results).reset_index(drop=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['lyrics'] = lyrics_series\n",
    "    \n",
    "    return df, no_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks = pd.read_csv(\"data/tracks.csv\")\n",
    "\n",
    "# Llamar a la función get_lyrics\n",
    "df_tracks_lyrics, no_lyrics = get_lyrics(df_tracks, batch_size=100, pause_time=0.5, n_jobs=8, token=\"NTWXUPKn3DXfY9SIpoX30G0HVcjH3GSskIk0KURIsxXQaXjCr0ljIq5IyLA5y7p0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks_lyrics.to_json(\"data/more_playlists.json\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
