{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chile\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo data/df_lyrics_clean.json\n",
    "df_tracks = pd.read_json('data/df_lyrics_clean.json')\n",
    "# Leer el archivo data/playlist.csv\n",
    "df_playlist = pd.read_csv('data/playlist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear los conjuntos de entrenamiento y prueba\n",
    "def create_train_test_sets(df, test_fraction=0.2):\n",
    "    # Listas para almacenar los conjuntos de datos de prueba y entrenamiento\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    \n",
    "    # Iterar sobre cada pid único\n",
    "    for pid, group in df.groupby('pid'):\n",
    "        # Seleccionar aleatoriamente el 20% de las canciones del grupo actual\n",
    "        test_indices = group.sample(frac=test_fraction).index\n",
    "        test_set = group.loc[test_indices]\n",
    "        train_set = group.drop(test_indices)\n",
    "        \n",
    "        # Agregar los resultados a las listas\n",
    "        train_list.append(train_set)\n",
    "        test_list.append(test_set)\n",
    "    \n",
    "    # Concatenar todos los grupos de entrenamiento y prueba en dos DataFrames\n",
    "    train_set = pd.concat(train_list).reset_index(drop=True)\n",
    "    test_set = pd.concat(test_list).reset_index(drop=True)\n",
    "    \n",
    "    return train_set, test_set\n",
    "\n",
    "# Crear los conjuntos de entrenamiento y prueba\n",
    "train_data, test_data = create_train_test_sets(df_playlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Verifica si hay una GPU disponible\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Usa GPU\n",
    "    print(f\"GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Usa CPU si no hay GPU disponible\n",
    "    print(\"GPU no disponible, usando CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "# Verifica si hay una GPU disponible y configúrala como dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Cargar el modelo y tokenizer de DistilBERT\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased').to(device)  # Mueve el modelo a la GPU si está disponible\n",
    "\n",
    "# Función para obtener embeddings\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True, padding='max_length').to(device)  # Mueve los inputs a la GPU\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Mueve los outputs de vuelta a la CPU para convertir a numpy\n",
    "\n",
    "# Filtrar los track ids en el conjunto de entrenamiento\n",
    "train_tids = train_data['tid'].unique()\n",
    "\n",
    "# Crear un diccionario para almacenar los embeddings de entrenamiento\n",
    "embeddings_dict_train = {}\n",
    "\n",
    "# Generar embeddings solo para los tracks en el conjunto de entrenamiento\n",
    "for tid in train_tids:\n",
    "    track_info = df_tracks[df_tracks['tid'] == tid].iloc[0]\n",
    "    content = f\"{track_info['track_name']} {track_info['album_name']} {track_info['artist_name']} {track_info['lyrics']}\"\n",
    "    embeddings_dict_train[tid] = get_embeddings(content)\n",
    "\n",
    "# Ahora los embeddings están almacenados en embeddings_dict_train y se han generado usando la GPU para acelerar el proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los embeddings junto con su track id\n",
    "with open('data/embeddings_train.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings_dict_train, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
