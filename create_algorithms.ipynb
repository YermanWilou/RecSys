{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer data/train_data.csv\n",
    "train_data = pd.read_csv('data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el pickle embeddings_train.pkl\n",
    "with open('data/embeddings_train.pkl', 'rb') as f:\n",
    "    embeddings_dict_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el diccionario de embeddings a una matriz\n",
    "track_ids = list(embeddings_dict_train.keys())\n",
    "embeddings_matrix = np.array([embeddings_dict_train[tid] for tid in track_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=104)\n",
    "embeddings_matrix_reduced = pca.fit_transform(embeddings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Supongamos que train_data es tu DataFrame con 'pid' y 'tid'\n",
    "# Y embeddings_dict_train es tu diccionario de embeddings\n",
    "\n",
    "# Crear una lista de listas donde cada sublista contiene los track ids de una playlist\n",
    "playlist_tracks = train_data.groupby('pid')['tid'].apply(list).tolist()\n",
    "\n",
    "# Crear una matriz de interacción (playlists x tracks)\n",
    "mlb = MultiLabelBinarizer()\n",
    "interaction_matrix = mlb.fit_transform(playlist_tracks)\n",
    "\n",
    "# Convertir a DataFrame para facilitar el manejo\n",
    "interaction_df = pd.DataFrame(interaction_matrix, columns=mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from annoy import AnnoyIndex\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# Parámetros\n",
    "embedding_dim = embeddings_matrix_reduced.shape[1]  # Dimensión de los embeddings reducidos\n",
    "hidden_dim = 128\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir embeddings_matrix_reduced a tensor\n",
    "embeddings_tensor = torch.tensor(embeddings_matrix_reduced, dtype=torch.float32)\n",
    "\n",
    "# Crear DataLoader\n",
    "dataset = TensorDataset(embeddings_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Inicializar el modelo, criterio y optimizador\n",
    "model = Autoencoder(embedding_dim, hidden_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.0739\n",
      "Epoch [2/50], Loss: 0.0882\n",
      "Epoch [3/50], Loss: 0.0701\n",
      "Epoch [4/50], Loss: 0.0784\n",
      "Epoch [5/50], Loss: 0.0738\n",
      "Epoch [6/50], Loss: 0.0706\n",
      "Epoch [7/50], Loss: 0.0758\n",
      "Epoch [8/50], Loss: 0.0737\n",
      "Epoch [9/50], Loss: 0.0674\n",
      "Epoch [10/50], Loss: 0.0767\n",
      "Epoch [11/50], Loss: 0.0764\n",
      "Epoch [12/50], Loss: 0.0788\n",
      "Epoch [13/50], Loss: 0.0767\n",
      "Epoch [14/50], Loss: 0.0803\n",
      "Epoch [15/50], Loss: 0.0750\n",
      "Epoch [16/50], Loss: 0.0656\n",
      "Epoch [17/50], Loss: 0.0606\n",
      "Epoch [18/50], Loss: 0.0733\n",
      "Epoch [19/50], Loss: 0.0606\n",
      "Epoch [20/50], Loss: 0.0666\n",
      "Epoch [21/50], Loss: 0.0717\n",
      "Epoch [22/50], Loss: 0.0813\n",
      "Epoch [23/50], Loss: 0.0758\n",
      "Epoch [24/50], Loss: 0.0943\n",
      "Epoch [25/50], Loss: 0.0664\n",
      "Epoch [26/50], Loss: 0.0646\n",
      "Epoch [27/50], Loss: 0.0803\n",
      "Epoch [28/50], Loss: 0.0797\n",
      "Epoch [29/50], Loss: 0.0709\n",
      "Epoch [30/50], Loss: 0.0693\n",
      "Epoch [31/50], Loss: 0.0753\n",
      "Epoch [32/50], Loss: 0.0731\n",
      "Epoch [33/50], Loss: 0.0710\n",
      "Epoch [34/50], Loss: 0.0690\n",
      "Epoch [35/50], Loss: 0.0599\n",
      "Epoch [36/50], Loss: 0.0681\n",
      "Epoch [37/50], Loss: 0.0940\n",
      "Epoch [38/50], Loss: 0.0813\n",
      "Epoch [39/50], Loss: 0.0665\n",
      "Epoch [40/50], Loss: 0.0839\n",
      "Epoch [41/50], Loss: 0.0839\n",
      "Epoch [42/50], Loss: 0.0759\n",
      "Epoch [43/50], Loss: 0.0622\n",
      "Epoch [44/50], Loss: 0.0728\n",
      "Epoch [45/50], Loss: 0.0698\n",
      "Epoch [46/50], Loss: 0.0725\n",
      "Epoch [47/50], Loss: 0.0824\n",
      "Epoch [48/50], Loss: 0.0841\n",
      "Epoch [49/50], Loss: 0.0639\n",
      "Epoch [50/50], Loss: 0.0724\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del autoencoder\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        inputs = data[0]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "torch.save(model.state_dict(), 'autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=104, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=104, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar modelo entrenado\n",
    "model = Autoencoder(embedding_dim, hidden_dim)\n",
    "model.load_state_dict(torch.load('autoencoder.pth'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las representaciones comprimidas (embeddings de playlists)\n",
    "def get_playlist_embeddings(playlist_track_ids):\n",
    "    track_embeddings = embeddings_matrix[playlist_track_ids]\n",
    "    track_embeddings_tensor = torch.tensor(track_embeddings, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        playlist_embedding = model.encoder(track_embeddings_tensor)\n",
    "    return playlist_embedding.mean(dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesado lote 1/147\n",
      "Procesado lote 2/147\n",
      "Procesado lote 3/147\n",
      "Procesado lote 4/147\n",
      "Procesado lote 5/147\n",
      "Procesado lote 6/147\n",
      "Procesado lote 7/147\n",
      "Procesado lote 8/147\n",
      "Procesado lote 9/147\n",
      "Procesado lote 10/147\n",
      "Procesado lote 11/147\n",
      "Procesado lote 12/147\n",
      "Procesado lote 13/147\n",
      "Procesado lote 14/147\n",
      "Procesado lote 15/147\n",
      "Procesado lote 16/147\n",
      "Procesado lote 17/147\n",
      "Procesado lote 18/147\n",
      "Procesado lote 19/147\n",
      "Procesado lote 20/147\n",
      "Procesado lote 21/147\n",
      "Procesado lote 22/147\n",
      "Procesado lote 23/147\n",
      "Procesado lote 24/147\n",
      "Procesado lote 25/147\n",
      "Procesado lote 26/147\n",
      "Procesado lote 27/147\n",
      "Procesado lote 28/147\n",
      "Procesado lote 29/147\n",
      "Procesado lote 30/147\n",
      "Procesado lote 31/147\n",
      "Procesado lote 32/147\n",
      "Procesado lote 33/147\n",
      "Procesado lote 34/147\n",
      "Procesado lote 35/147\n",
      "Procesado lote 36/147\n",
      "Procesado lote 37/147\n",
      "Procesado lote 38/147\n",
      "Procesado lote 39/147\n",
      "Procesado lote 40/147\n",
      "Procesado lote 41/147\n",
      "Procesado lote 42/147\n",
      "Procesado lote 43/147\n",
      "Procesado lote 44/147\n",
      "Procesado lote 45/147\n",
      "Procesado lote 46/147\n",
      "Procesado lote 47/147\n",
      "Procesado lote 48/147\n",
      "Procesado lote 49/147\n",
      "Procesado lote 50/147\n",
      "Procesado lote 51/147\n",
      "Procesado lote 52/147\n",
      "Procesado lote 53/147\n",
      "Procesado lote 54/147\n",
      "Procesado lote 55/147\n",
      "Procesado lote 56/147\n",
      "Procesado lote 57/147\n",
      "Procesado lote 58/147\n",
      "Procesado lote 59/147\n",
      "Procesado lote 60/147\n",
      "Procesado lote 61/147\n",
      "Procesado lote 62/147\n",
      "Procesado lote 63/147\n",
      "Procesado lote 64/147\n",
      "Procesado lote 65/147\n",
      "Procesado lote 66/147\n",
      "Procesado lote 67/147\n",
      "Procesado lote 68/147\n",
      "Procesado lote 69/147\n",
      "Procesado lote 70/147\n",
      "Procesado lote 71/147\n",
      "Procesado lote 72/147\n",
      "Procesado lote 73/147\n",
      "Procesado lote 74/147\n",
      "Procesado lote 75/147\n",
      "Procesado lote 76/147\n",
      "Procesado lote 77/147\n",
      "Procesado lote 78/147\n",
      "Procesado lote 79/147\n",
      "Procesado lote 80/147\n",
      "Procesado lote 81/147\n",
      "Procesado lote 82/147\n",
      "Procesado lote 83/147\n",
      "Procesado lote 84/147\n",
      "Procesado lote 85/147\n",
      "Procesado lote 86/147\n",
      "Procesado lote 87/147\n",
      "Procesado lote 88/147\n",
      "Procesado lote 89/147\n",
      "Procesado lote 90/147\n",
      "Procesado lote 91/147\n",
      "Procesado lote 92/147\n",
      "Procesado lote 93/147\n",
      "Procesado lote 94/147\n",
      "Procesado lote 95/147\n",
      "Procesado lote 96/147\n",
      "Procesado lote 97/147\n",
      "Procesado lote 98/147\n",
      "Procesado lote 99/147\n",
      "Procesado lote 100/147\n",
      "Procesado lote 101/147\n",
      "Procesado lote 102/147\n",
      "Procesado lote 103/147\n",
      "Procesado lote 104/147\n",
      "Procesado lote 105/147\n",
      "Procesado lote 106/147\n",
      "Procesado lote 107/147\n",
      "Procesado lote 108/147\n",
      "Procesado lote 109/147\n",
      "Procesado lote 110/147\n",
      "Procesado lote 111/147\n",
      "Procesado lote 112/147\n",
      "Procesado lote 113/147\n",
      "Procesado lote 114/147\n",
      "Procesado lote 115/147\n",
      "Procesado lote 116/147\n",
      "Procesado lote 117/147\n",
      "Procesado lote 118/147\n",
      "Procesado lote 119/147\n",
      "Procesado lote 120/147\n",
      "Procesado lote 121/147\n",
      "Procesado lote 122/147\n",
      "Procesado lote 123/147\n",
      "Procesado lote 124/147\n",
      "Procesado lote 125/147\n",
      "Procesado lote 126/147\n",
      "Procesado lote 127/147\n",
      "Procesado lote 128/147\n",
      "Procesado lote 129/147\n",
      "Procesado lote 130/147\n",
      "Procesado lote 131/147\n",
      "Procesado lote 132/147\n",
      "Procesado lote 133/147\n",
      "Procesado lote 134/147\n",
      "Procesado lote 135/147\n",
      "Procesado lote 136/147\n",
      "Procesado lote 137/147\n",
      "Procesado lote 138/147\n",
      "Procesado lote 139/147\n",
      "Procesado lote 140/147\n",
      "Procesado lote 141/147\n",
      "Procesado lote 142/147\n",
      "Procesado lote 143/147\n",
      "Procesado lote 144/147\n",
      "Procesado lote 145/147\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Construir el índice Annoy\n",
    "def build_annoy_index(embeddings_tensor, batch_size=1000):\n",
    "    index = AnnoyIndex(hidden_dim, 'angular')\n",
    "    num_batches = len(embeddings_tensor) // batch_size + 1\n",
    "\n",
    "    for batch in range(num_batches):\n",
    "        start = batch * batch_size\n",
    "        end = min((batch + 1) * batch_size, len(embeddings_tensor))\n",
    "        batch_embeddings = embeddings_tensor[start:end]\n",
    "\n",
    "        for i, embedding in enumerate(batch_embeddings):\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    compressed_embedding = model.encoder(embedding.unsqueeze(0)).squeeze()\n",
    "                index.add_item(start + i, compressed_embedding.numpy())\n",
    "            except Exception as e:\n",
    "                print(f\"Error en batch {batch + 1}, índice {i}: {str(e)}\")\n",
    "        \n",
    "        # Liberar memoria de los embeddings y el modelo en cada lote\n",
    "        del batch_embeddings\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f'Procesado lote {batch + 1}/{num_batches}')\n",
    "\n",
    "    index.build(100)  # Ajustar el número de árboles según sea necesario\n",
    "    return index\n",
    "\n",
    "# Construir y guardar el índice Annoy\n",
    "try:\n",
    "    index = build_annoy_index(embeddings_tensor)\n",
    "    index.save('annoy_index.ann')\n",
    "except Exception as e:\n",
    "    print(f\"Error al construir el índice Annoy: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
